# ğŸ¤– Agent Management Platform

**Sistema de GestÃ£o de Agentes de IA com LangGraph + RAG**

## ğŸ“‹ DescriÃ§Ã£o do Projeto

API desenvolvida como desafio tÃ©cnico para a vaga de Engenheiro(a) de Software Full Stack SÃªnior.  
O sistema permite a criaÃ§Ã£o, gestÃ£o e orquestraÃ§Ã£o de agentes de InteligÃªncia Artificial utilizando **LangGraph**, com um CRUD completo para gerenciamento de prompts, integraÃ§Ã£o com **RAG** (Retrieval-Augmented Generation) e interface visual para manipulaÃ§Ã£o de prompts.

### ğŸ¯ Objetivo

Demonstrar competÃªncias em:
- Desenvolvimento backend com Python (FastAPI)
- ImplementaÃ§Ã£o de sistemas com IA/LLMs (LangGraph + RAG)
- Arquitetura escalÃ¡vel e boas prÃ¡ticas de desenvolvimento
- GestÃ£o de agentes autÃ´nomos com diferentes especialidades
- IntegraÃ§Ã£o frontend/backend com Vue 3 + Vite

---

## ğŸ—ï¸ Arquitetura do Sistema

- **API REST (FastAPI)** â†’ operaÃ§Ãµes CRUD de agentes e prompts  
- **Agentes AutÃ´nomos** â†’ orquestrados via LangGraph  
- **RAG** â†’ indexaÃ§Ã£o/consulta de documentos no ChromaDB  
- **PersistÃªncia** â†’ PostgreSQL (dados) + Redis (cache/memÃ³ria)  
- **LLM Provider** â†’ Ollama (Llama3 + embeddings nomic-embed-text)  
- **Frontend** â†’ Vue 3 + Vite para CRUD de prompts e execuÃ§Ã£o de agentes  
- **Infra** â†’ Docker + Docker Compose  
- **Extras** â†’ Logging centralizado, middleware de erros, CI/CD no GitHub Actions  

---

## ğŸš€ Funcionalidades Principais

### 1. Sistema de Agentes
- Agentes especializados para diferentes tarefas
- ExecuÃ§Ã£o via `/api/v1/agents/{id}/run`
- ConfiguraÃ§Ã£o dinÃ¢mica (modelo, temperatura, base_url)

### 2. CRUD de Prompts
- Criar, editar, listar e excluir prompts
- ValidaÃ§Ã£o de estrutura
- Versionamento bÃ¡sico

### 3. RAG (Retrieval-Augmented Generation)
- Upload de documentos (PDF, TXT, MD) via `/api/v1/rag/upload`
- Consulta contextualizada via `/api/v1/rag/query`
- IndexaÃ§Ã£o persistente em `chroma_db/`

### 4. Memory Management *(em progresso)*
- Suporte a histÃ³rico de conversas (armazenado em Redis)

### 5. Monitoramento e Custos *(planejado)*
- Acompanhamento de execuÃ§Ãµes
- CÃ¡lculo simulado de custo por agente

---

## ğŸ’» Stack TecnolÃ³gica

- **Backend**: Python 3.10+, FastAPI, SQLAlchemy, LangGraph, LangChain  
- **Banco**: PostgreSQL 15  
- **Cache**: Redis 7  
- **Vector DB**: ChromaDB  
- **LLM**: Ollama (modelos locais)  
- **Frontend**: Vue 3 + Vite  
- **Infra**: Docker, Docker Compose, GitHub Actions (CI/CD)  

---

## ğŸ”§ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### PrÃ©-requisitos
- Docker e Docker Compose
- Python 3.10+ (para rodar local se quiser)
- PostgreSQL 15+
- Redis 7+

### Setup Local
```bash
git clone https://github.com/RonaldoAmaralDev/desafio-agent.git
cd desafio-agent
cp .env.example .env
# edite variÃ¡veis do .env se necessÃ¡rio
docker compose up --build
```

### Acesso
- API: http://localhost:8000/docs  
- Health Check: http://localhost:8000/health  
- Frontend: http://localhost:5173  

---

## ğŸ“Š Exemplos de Uso

### Criar Agente
```http
POST /api/v1/agents
{
  "name": "Research Assistant",
  "model": "llama3",
  "temperature": 0.7
}
```

### Executar Agente
```http
POST /api/v1/agents/{agent_id}/run
{
  "input": "Explique a importÃ¢ncia da RevoluÃ§Ã£o Industrial"
}
```

### Upload de Documento
```http
POST /api/v1/rag/upload
(file=@documento.pdf)
```

### Perguntar com RAG
```http
POST /api/v1/rag/query
{
  "question": "O que este documento fala sobre IA?"
}
```

---

## ğŸ§ª Testes
```bash
pytest tests/ --cov=src
```

---

## ğŸ“ˆ Diferenciais Implementados
- Multi-Agent Collaboration (em evoluÃ§Ã£o)
- Prompt Engineering Interface (frontend Vue)
- RAG integrado (Chroma + Ollama)
- Logging em todas as rotas
- Middleware para tratamento de erros
- CI/CD configurado (GitHub Actions)
- Volume persistente para embeddings (Chroma) e modelos (Ollama)

---

## ğŸ—ºï¸ Roadmap Futuro

1. **Memory Management Completo**: manter histÃ³rico de conversas em Redis por sessÃ£o/usuÃ¡rio.  
2. **Real-time Monitoring**: dashboard de execuÃ§Ãµes em tempo real.  
3. **Cost Tracking real**: cÃ¡lculo de custo baseado em tokens gerados.  
4. **Interface Frontend AvanÃ§ada**: incluir visualizaÃ§Ã£o de execuÃ§Ãµes e upload de documentos direto na interface.  
5. **Suporte a mÃºltiplos providers**: alÃ©m de Ollama, permitir OpenAI/Azure.  

---

## ğŸ“ Notas sobre o Desafio
Este projeto foi desenvolvido como resposta ao desafio tÃ©cnico, demonstrando:
- **CompetÃªncia Backend** com FastAPI e SQLAlchemy  
- **Conhecimento em IA** com LangGraph + RAG  
- **Boas PrÃ¡ticas**: testes, logging, documentaÃ§Ã£o, Docker  
- **VisÃ£o de Produto**: integra backend, frontend e LLMs em um sistema Ãºnico  
